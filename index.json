[
  {
    "authors": "admin",
    "categories": null,
    "content": "Hi there! I'm Ahmad, an M.Sc. student in Computer Science at York University, working under the supervision of <a href=\"https://csprofkgd.github.io/\" target=\"_blank\" rel=\"noopener\">Kosta Derpanis</a> as a member of the <a href=\"https://yorkucvil.github.io/\" target=\"_blank\" rel=\"noopener\">CVIL Lab</a>. My research focuses on artificial intelligence, particularly computer vision. I'm especially interested in generative modeling, with a focus on Diffusion Models and their controllability in 3D Vision.",
    "kind": "term",
    "lang": "en",
    "objecID": "f2ea376fee8b97d279a5f2b04ebc7f8e",
    "permalink": "https://geomvi.github.io/#about",
    "relpermalink": "/#about",
    "section": "about",
    "summary": "Hi there! I'm Ahmad, an M.Sc. student in Computer Science at York University, working under the supervision of <a href=\"https://csprofkgd.github.io/\" target=\"_blank\" rel=\"noopener\">Kosta Derpanis</a> as a member of the <a href=\"https://yorkucvil.github.io/\" target=\"_blank\" rel=\"noopener\">CVIL Lab</a>. My research focuses on artificial intelligence, particularly computer vision. I'm especially interested in generative modeling, with a focus on Diffusion Models and their controllability in 3D Vision.",
    "tags": null,
    "title": "About",
    "type": "about"
  },
  {
    "authors": "admin",
    "categories": null,
    "content": "I started a research internship at Ubisoft La Forge Toronto.",
    "kind": "term",
    "lang": "en",
    "objecID": "427807e60c04c8b42af2dbfd1e7bd393",
    "permalink": "https://geomvi.github.io/#news",
    "relpermalink": "/#news",
    "section": "news",
    "summary": "I started a research internship at Ubisoft La Forge Toronto.",
    "tags": null,
    "title": "I started a research internship at Ubisoft La Forge Toronto.",
    "type": "news"
  },
  {
    "authors": "admin",
    "categories": null,
    "content": "I joined <a href=\"https://yorkucvil.github.io/\" target=\"_blank\" rel=\"noopener\">Computational Vision and Imaging Lab</a> as a Research Assistant.",
    "kind": "term",
    "lang": "en",
    "objecID": "06451e39ecb1d6b8c21d91e2261dd522",
    "permalink": "https://geomvi.github.io/#news",
    "relpermalink": "/#news",
    "section": "news",
    "summary": "I joined <a href=\"https://yorkucvil.github.io/\" target=\"_blank\" rel=\"noopener\">Computational Vision and Imaging Lab</a> as a Research Assistant.",
    "tags": null,
    "title": "I joined <a href=\"https://yorkucvil.github.io/\" target=\"_blank\" rel=\"noopener\">Computational Vision and Imaging Lab</a> as a Research Assistant.",
    "type": "news"
  },
  {
    "authors": "admin",
    "categories": null,
    "content": "I accepted the <a href=\"https://vista.info.yorku.ca/opportunities/masters-scholarships/\" target=\"_blank\" rel=\"noopener\">VISTA Graduate Scholarship</a> at York University.",
    "kind": "term",
    "lang": "en",
    "objecID": "8c21bad08fbd0de04f124acf6399dfc0",
    "permalink": "https://geomvi.github.io/#news",
    "relpermalink": "/#news",
    "section": "news",
    "summary": "I accepted the <a href=\"https://vista.info.yorku.ca/opportunities/masters-scholarships/\" target=\"_blank\" rel=\"noopener\">VISTA Graduate Scholarship</a> at York University.",
    "tags": null,
    "title": "I accepted the <a href=\"https://vista.info.yorku.ca/opportunities/masters-scholarships/\" target=\"_blank\" rel=\"noopener\">VISTA Graduate Scholarship</a> at York University.",
    "type": "news"
  },
  {
    "authors": "admin",
    "categories": null,
    "content": "I accepted the <a href=\"https://vectorinstitute.ai/programs/scholarship/\" target=\"_blank\" rel=\"noopener\">Vector Scholarship in Artificial Intelligence</a> from Vector Institute.",
    "kind": "term",
    "lang": "en",
    "objecID": "17983c68f39bf5f7bc7beab63f3f381d",
    "permalink": "https://geomvi.github.io/#news",
    "relpermalink": "/#news",
    "section": "news",
    "summary": "I accepted the <a href=\"https://vectorinstitute.ai/programs/scholarship/\" target=\"_blank\" rel=\"noopener\">Vector Scholarship in Artificial Intelligence</a> from Vector Institute.",
    "tags": null,
    "title": "I accepted the <a href=\"https://vectorinstitute.ai/programs/scholarship/\" target=\"_blank\" rel=\"noopener\">Vector Scholarship in Artificial Intelligence</a> from Vector Institute.",
    "type": "news"
  },
  {
    "authors": "admin",
    "categories": null,
    "content": "I got accepted to York University Masters of Science program in Computer Science.",
    "kind": "term",
    "lang": "en",
    "objecID": "044f8b3bafddf598db6134d2f6bdb7a6",
    "permalink": "https://geomvi.github.io/#news",
    "relpermalink": "/#news",
    "section": "news",
    "summary": "I got accepted to York University Masters of Science program in Computer Science.",
    "tags": null,
    "title": "I got accepted to York University Masters of Science program in Computer Science.",
    "type": "news"
  },
  {
    "authors": "Ahmad Salimi, Tristan Aumentado-Armstrong, Marcus A. Brubaker, Konstantinos G. Derpanis",
    "categories": [],
    "content": "In this paper, we focus on 3D scene inpainting, where parts of an input image set, captured from different viewpoints, are masked out. The main challenge lies in generating plausible image completions that are geometrically consistent across views. Most recent work addresses this challenge by combining generative models with a 3D radiance field to fuse information across viewpoints. However, a major drawback of these methods is that they often produce blurry images due to the fusion of inconsistent cross-view images. To avoid blurry inpaintings, we eschew the use of an explicit or implicit radiance field altogether and instead fuse cross-view information in a learned space. In particular, we introduce a geometry-aware conditional generative model, capable of inpainting multi-view consistent images based on both geometric and appearance cues from reference images. A key advantage of our approach over existing methods is its unique ability to inpaint masked scenes with a limited number of views (i.e., few-view inpainting), whereas previous methods require relatively large image sets for their 3D model fitting step. Empirically, we evaluate and compare our scene-centric inpainting method on two datasets, SPIn-NeRF and NeRFiller, which contain images captured at narrow and wide baselines, respectively, and achieve state-of-the-art 3D inpainting performance on both. Additionally, we demonstrate the efficacy of our approach in the few-view setting compared to prior methods.",
    "kind": "term",
    "lang": "en",
    "objecID": "94911ee8bd8dda5e9a5006856053f163",
    "permalink": "https://geomvi.github.io/#publications",
    "relpermalink": "/#publications",
    "section": "publications",
    "summary": "In this paper, we focus on 3D scene inpainting, where parts of an input image set, captured from different viewpoints, are masked out. The main challenge lies in generating plausible image completions that are geometrically consistent across views. Most recent work addresses this challenge by combining generative models with a 3D radiance field to fuse information across viewpoints. However, a major drawback of these methods is that they often produce blurry images due to the fusion of inconsistent cross-view images. To avoid blurry inpaintings, we eschew the use of an explicit or implicit radiance field altogether and instead fuse cross-view information in a learned space. In particular, we introduce a geometry-aware conditional generative model, capable of inpainting multi-view consistent images based on both geometric and appearance cues from reference images. A key advantage of our approach over existing methods is its unique ability to inpaint masked scenes with a limited number of views (i.e., few-view inpainting), whereas previous methods require relatively large image sets for their 3D model fitting step. Empirically, we evaluate and compare our scene-centric inpainting method on two datasets, SPIn-NeRF and NeRFiller, which contain images captured at narrow and wide baselines, respectively, and achieve state-of-the-art 3D inpainting performance on both. Additionally, we demonstrate the efficacy of our approach in the few-view setting compared to prior methods.",
    "tags": null,
    "title": "Geometry-Aware Diffusion Models for Multiview Scene Inpainting",
    "type": "publication"
  }
]